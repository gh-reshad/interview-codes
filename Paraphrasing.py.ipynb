{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/greshad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/greshad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "download('stopwords')\n",
    "download('punkt')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    #doc = doc.lower() #Lowercase the text\n",
    "    doc = word_tokenize(doc) #split into words\n",
    "    doc = [w for w in doc if not w in stop_words] #Remove stop words\n",
    "    doc = [w for w in doc if w.isalpha()] # Remove punctuation and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = ['Charlie Chan is off the case for the Fox Movie Channel',\n",
    "      'The Fox Movie Channel has banned Charlie Chan.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.KeyedVectors.load_word2vec_format('/home/greshad/Downloads/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(doc)):\n",
    "    data.append(doc[i].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wmdistance` (Method will be removed in 4.0.0, use self.wv.wmdistance() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "distance = model.wmdistance(data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wmdistance` (Method will be removed in 4.0.0, use self.wv.wmdistance() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1031e454560f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwmdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'similarity: %i'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "        dist = model.wmdistance(data[i][j], data[i+1][j])\n",
    "        print(data[i][j], data[i+1][j], 'similarity: %i'%dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(data, min_count = 1, size = 50, workers = 3, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlie 2 top similar words: [('off', 0.21667446196079254), ('banned', 0.2019852101802826), ('case', 0.09971624612808228), ('is', 0.05579208955168724)] \n",
      "\n",
      "Chan 2 top similar words: [('Fox', 0.17082208395004272), ('has', 0.13164964318275452), ('case', 0.12448784708976746), ('the', 0.08910951018333435)] \n",
      "\n",
      "is 2 top similar words: [('Fox', 0.1813373565673828), ('has', 0.09637661278247833), ('Channel', 0.08948951214551926), ('the', 0.06281286478042603)] \n",
      "\n",
      "off 2 top similar words: [('Charlie', 0.21667446196079254), ('Chan.', 0.10348866879940033), ('has', -0.006736829876899719), ('banned', -0.012216399423778057)] \n",
      "\n",
      "the 2 top similar words: [('case', 0.19245223701000214), ('Fox', 0.17302817106246948), ('Chan', 0.08910951018333435), ('is', 0.06281286478042603)] \n",
      "\n",
      "case 2 top similar words: [('banned', 0.20849353075027466), ('the', 0.19245223701000214), ('Channel', 0.187668114900589), ('Chan', 0.12448784708976746)] \n",
      "\n",
      "for 2 top similar words: [('has', 0.28920531272888184), ('Fox', 0.1754852533340454), ('Channel', 0.12151604145765305), ('The', 0.0811767727136612)] \n",
      "\n",
      "the 2 top similar words: [('case', 0.19245223701000214), ('Fox', 0.17302817106246948), ('Chan', 0.08910951018333435), ('is', 0.06281286478042603)] \n",
      "\n",
      "Fox 2 top similar words: [('Channel', 0.22395819425582886), ('is', 0.1813373565673828), ('for', 0.1754852533340454), ('the', 0.17302817106246948)] \n",
      "\n",
      "Movie 2 top similar words: [('Chan.', 0.10953495651483536), ('Fox', 0.06332609802484512), ('banned', 0.05398162454366684), ('is', 0.02685525454580784)] \n",
      "\n",
      "Channel 2 top similar words: [('Fox', 0.22395819425582886), ('The', 0.2225777953863144), ('case', 0.187668114900589), ('banned', 0.17984692752361298)] \n",
      "\n",
      "The 2 top similar words: [('has', 0.3013320863246918), ('Channel', 0.2225777804851532), ('Chan.', 0.14606694877147675), ('for', 0.0811767652630806)] \n",
      "\n",
      "Fox 2 top similar words: [('Channel', 0.22395819425582886), ('is', 0.1813373565673828), ('for', 0.1754852533340454), ('the', 0.17302817106246948)] \n",
      "\n",
      "Movie 2 top similar words: [('Chan.', 0.10953495651483536), ('Fox', 0.06332609802484512), ('banned', 0.05398162454366684), ('is', 0.02685525454580784)] \n",
      "\n",
      "Channel 2 top similar words: [('Fox', 0.22395819425582886), ('The', 0.2225777953863144), ('case', 0.187668114900589), ('banned', 0.17984692752361298)] \n",
      "\n",
      "has 2 top similar words: [('The', 0.30133214592933655), ('for', 0.28920531272888184), ('Fox', 0.13180744647979736), ('Chan', 0.13164964318275452)] \n",
      "\n",
      "banned 2 top similar words: [('case', 0.20849350094795227), ('Charlie', 0.2019852101802826), ('Channel', 0.17984692752361298), ('Chan.', 0.14971987903118134)] \n",
      "\n",
      "Charlie 2 top similar words: [('off', 0.21667446196079254), ('banned', 0.2019852101802826), ('case', 0.09971624612808228), ('is', 0.05579208955168724)] \n",
      "\n",
      "Chan. 2 top similar words: [('banned', 0.14971987903118134), ('The', 0.14606694877147675), ('Movie', 0.10953495651483536), ('off', 0.10348868370056152)] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "        word = data[i][j]\n",
    "        print(word, '2 top similar words:', model.most_similar(word, topn= 4), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
